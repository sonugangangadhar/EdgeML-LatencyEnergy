{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10321243,"sourceType":"datasetVersion","datasetId":6390297}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\nimport joblib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-10T00:52:16.183758Z","iopub.execute_input":"2025-01-10T00:52:16.184201Z","iopub.status.idle":"2025-01-10T00:52:16.190847Z","shell.execute_reply.started":"2025-01-10T00:52:16.184169Z","shell.execute_reply":"2025-01-10T00:52:16.189346Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Function to preprocess the dataset\ndef preprocess_data(file_path, target_columns, look_back=5):\n    \"\"\"\n    Preprocess the dataset and reshape it for LSTM.\n    \"\"\"\n    data = pd.read_excel(file_path)\n    data.columns = data.iloc[0]\n    data = data[1:]\n    data = data.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n    data.fillna(data.mean(), inplace=True)\n\n    X = data.drop(target_columns, axis=1).values\n    y = data[target_columns].values\n\n    # Standardize the features\n    scaler_X = StandardScaler()\n    scaler_y = StandardScaler()\n    X = scaler_X.fit_transform(X)\n    y = scaler_y.fit_transform(y)\n\n    # Create sequences for the LSTM\n    X_seq, y_seq = [], []\n    for i in range(len(X) - look_back):\n        X_seq.append(X[i:i + look_back])  # Keep 3D shape for LSTM\n        y_seq.append(y[i + look_back])\n    X_seq = np.array(X_seq)\n    y_seq = np.array(y_seq)\n\n    return X_seq, y_seq, scaler_X, scaler_y\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T00:52:16.192535Z","iopub.execute_input":"2025-01-10T00:52:16.193014Z","iopub.status.idle":"2025-01-10T00:52:16.212201Z","shell.execute_reply.started":"2025-01-10T00:52:16.192956Z","shell.execute_reply":"2025-01-10T00:52:16.210878Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Function to preprocess testing data using the same scalers\ndef preprocess_test_data(file_path, target_columns, scaler_X, scaler_y, look_back=5):\n    \"\"\"\n    Preprocess the testing dataset using the provided scalers.\n    \"\"\"\n    data = pd.read_excel(file_path)\n    data.columns = data.iloc[0]\n    data = data[1:]\n    data = data.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n    data.fillna(data.mean(), inplace=True)\n\n    X = data.drop(target_columns, axis=1).values\n    y = data[target_columns].values\n\n    X = scaler_X.transform(X)  # Standardize using training scaler\n    y = scaler_y.transform(y)  # Standardize using training scaler\n\n    # Create sequences for the LSTM\n    X_seq, y_seq = [], []\n    for i in range(len(X) - look_back):\n        X_seq.append(X[i:i + look_back])  # Keep 3D shape for LSTM\n        y_seq.append(y[i + look_back])\n    X_seq = np.array(X_seq)\n    y_seq = np.array(y_seq)\n\n    return X_seq, y_seq\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T00:52:16.214239Z","iopub.execute_input":"2025-01-10T00:52:16.214551Z","iopub.status.idle":"2025-01-10T00:52:16.224271Z","shell.execute_reply.started":"2025-01-10T00:52:16.214525Z","shell.execute_reply":"2025-01-10T00:52:16.222888Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# File paths\ntraining_file = '/kaggle/input/heterogenous-dataset/Training Dataset.xlsx'\ntesting_file = '/kaggle/input/heterogenous-dataset/Testing Dataset.xlsx'\ntarget_columns = ['Cloud_Throughput', 'Total_Energy_Consumption', 'Total_Exec_Time']\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T00:52:16.226114Z","iopub.execute_input":"2025-01-10T00:52:16.226565Z","iopub.status.idle":"2025-01-10T00:52:16.247855Z","shell.execute_reply.started":"2025-01-10T00:52:16.226534Z","shell.execute_reply":"2025-01-10T00:52:16.246599Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# ========================= TRAINING PHASE =========================\nlook_back = 5  # Number of past time steps for prediction\nX_train, y_train, scaler_X, scaler_y = preprocess_data(training_file, target_columns, look_back)\n\n# Build the LSTM model\nmodel = Sequential([\n    LSTM(64, activation='relu', return_sequences=True, input_shape=(look_back, X_train.shape[2]), kernel_regularizer=l2(0.001)),\n    Dropout(0.3),\n    LSTM(32, activation='relu', kernel_regularizer=l2(0.001)),\n    Dropout(0.3),\n    Dense(y_train.shape[1], activation='linear')\n])\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.0003), loss='mse', metrics=['mae'])\nprint(model.summary())\n\n# Callbacks\nearly_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, verbose=1)\n\n# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    validation_split=0.2,\n    epochs=200,\n    batch_size=16,\n    callbacks=[early_stopping, reduce_lr],\n    verbose=1\n)\n\n# Save the model and scalers\nmodel.save('lstm_model_fixed.keras')\njoblib.dump((scaler_X, scaler_y), 'lstm_scalers_fixed.pkl')\nprint(\"LSTM model and scalers saved successfully!\")\n\n# Evaluate training performance\ny_train_pred = model.predict(X_train)\ny_train = scaler_y.inverse_transform(y_train)\ny_train_pred = scaler_y.inverse_transform(y_train_pred)\n\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\n\nprint(\"\\nLSTM Training Metrics:\")\nprint(f\"RMSE: {train_rmse:.4f}, MAE: {train_mae:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T00:52:16.249089Z","iopub.execute_input":"2025-01-10T00:52:16.249502Z","iopub.status.idle":"2025-01-10T00:54:04.158339Z","shell.execute_reply.started":"2025-01-10T00:52:16.249461Z","shell.execute_reply":"2025-01-10T00:54:04.157180Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │          \u001b[38;5;34m26,368\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m99\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">26,368</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,883\u001b[0m (151.89 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,883</span> (151.89 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,883\u001b[0m (151.89 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,883</span> (151.89 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"None\nEpoch 1/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 1.3778 - mae: 0.4349 - val_loss: 0.2571 - val_mae: 0.2678 - learning_rate: 3.0000e-04\nEpoch 2/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.9990 - mae: 0.2562 - val_loss: 0.1924 - val_mae: 0.2063 - learning_rate: 3.0000e-04\nEpoch 3/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.6079 - mae: 0.2219 - val_loss: 0.1773 - val_mae: 0.2085 - learning_rate: 3.0000e-04\nEpoch 4/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.3516 - mae: 0.2130 - val_loss: 0.1515 - val_mae: 0.1655 - learning_rate: 3.0000e-04\nEpoch 5/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.0168 - mae: 0.2215 - val_loss: 0.1573 - val_mae: 0.1828 - learning_rate: 3.0000e-04\nEpoch 6/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.3590 - mae: 0.2021 - val_loss: 0.1523 - val_mae: 0.1892 - learning_rate: 3.0000e-04\nEpoch 7/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.3842 - mae: 0.1861 - val_loss: 0.1457 - val_mae: 0.1723 - learning_rate: 3.0000e-04\nEpoch 8/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.4763 - mae: 0.1881 - val_loss: 0.1395 - val_mae: 0.1693 - learning_rate: 3.0000e-04\nEpoch 9/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.7170 - mae: 0.1925 - val_loss: 0.1369 - val_mae: 0.1647 - learning_rate: 3.0000e-04\nEpoch 10/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.1679 - mae: 0.2001 - val_loss: 0.1350 - val_mae: 0.1592 - learning_rate: 3.0000e-04\nEpoch 11/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.0026 - mae: 0.1916 - val_loss: 0.1317 - val_mae: 0.1609 - learning_rate: 3.0000e-04\nEpoch 12/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.5857 - mae: 0.1823 - val_loss: 0.1285 - val_mae: 0.1600 - learning_rate: 3.0000e-04\nEpoch 13/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.7290 - mae: 0.1837 - val_loss: 0.1297 - val_mae: 0.1630 - learning_rate: 3.0000e-04\nEpoch 14/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.0233 - mae: 0.1857 - val_loss: 0.1148 - val_mae: 0.1308 - learning_rate: 3.0000e-04\nEpoch 15/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.7060 - mae: 0.1806 - val_loss: 0.1203 - val_mae: 0.1435 - learning_rate: 3.0000e-04\nEpoch 16/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.7135 - mae: 0.1973 - val_loss: 0.1204 - val_mae: 0.1521 - learning_rate: 3.0000e-04\nEpoch 17/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.3309 - mae: 0.1697 - val_loss: 0.1369 - val_mae: 0.1898 - learning_rate: 3.0000e-04\nEpoch 18/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.7442 - mae: 0.1766 - val_loss: 0.1178 - val_mae: 0.1501 - learning_rate: 3.0000e-04\nEpoch 19/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.8096 - mae: 0.1779 - val_loss: 0.1237 - val_mae: 0.1704 - learning_rate: 3.0000e-04\nEpoch 20/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.5692 - mae: 0.1756 - val_loss: 0.1207 - val_mae: 0.1650 - learning_rate: 3.0000e-04\nEpoch 21/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7117 - mae: 0.1785\nEpoch 21: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.7114 - mae: 0.1785 - val_loss: 0.1226 - val_mae: 0.1685 - learning_rate: 3.0000e-04\nEpoch 22/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.7442 - mae: 0.1715 - val_loss: 0.1099 - val_mae: 0.1418 - learning_rate: 1.5000e-04\nEpoch 23/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.3709 - mae: 0.1659 - val_loss: 0.1075 - val_mae: 0.1297 - learning_rate: 1.5000e-04\nEpoch 24/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.4201 - mae: 0.1706 - val_loss: 0.1110 - val_mae: 0.1390 - learning_rate: 1.5000e-04\nEpoch 25/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.6529 - mae: 0.1727 - val_loss: 0.1146 - val_mae: 0.1466 - learning_rate: 1.5000e-04\nEpoch 26/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.4005 - mae: 0.1675 - val_loss: 0.1094 - val_mae: 0.1392 - learning_rate: 1.5000e-04\nEpoch 27/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.4005 - mae: 0.1734 - val_loss: 0.1075 - val_mae: 0.1364 - learning_rate: 1.5000e-04\nEpoch 28/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.8103 - mae: 0.1797 - val_loss: 0.1077 - val_mae: 0.1369 - learning_rate: 1.5000e-04\nEpoch 29/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.0834 - mae: 0.1813 - val_loss: 0.1085 - val_mae: 0.1419 - learning_rate: 1.5000e-04\nEpoch 30/200\n\u001b[1m195/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5317 - mae: 0.1747\nEpoch 30: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.5339 - mae: 0.1746 - val_loss: 0.1135 - val_mae: 0.1532 - learning_rate: 1.5000e-04\nEpoch 31/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 2.3073 - mae: 0.2114 - val_loss: 0.1072 - val_mae: 0.1420 - learning_rate: 7.5000e-05\nEpoch 32/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.5946 - mae: 0.1656 - val_loss: 0.1079 - val_mae: 0.1403 - learning_rate: 7.5000e-05\nEpoch 33/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.1031 - mae: 0.1838 - val_loss: 0.1062 - val_mae: 0.1379 - learning_rate: 7.5000e-05\nEpoch 34/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.7835 - mae: 0.1717 - val_loss: 0.1069 - val_mae: 0.1364 - learning_rate: 7.5000e-05\nEpoch 35/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.8491 - mae: 0.1749 - val_loss: 0.1047 - val_mae: 0.1326 - learning_rate: 7.5000e-05\nEpoch 36/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.0756 - mae: 0.1792 - val_loss: 0.1064 - val_mae: 0.1396 - learning_rate: 7.5000e-05\nEpoch 37/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.6920 - mae: 0.1695 - val_loss: 0.1044 - val_mae: 0.1340 - learning_rate: 7.5000e-05\nEpoch 38/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.5017 - mae: 0.1869 - val_loss: 0.1043 - val_mae: 0.1350 - learning_rate: 7.5000e-05\nEpoch 39/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1778 - mae: 0.1602 - val_loss: 0.1133 - val_mae: 0.1545 - learning_rate: 7.5000e-05\nEpoch 40/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.5150 - mae: 0.1710 - val_loss: 0.1093 - val_mae: 0.1457 - learning_rate: 7.5000e-05\nEpoch 41/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.4836 - mae: 0.1712 - val_loss: 0.1045 - val_mae: 0.1325 - learning_rate: 7.5000e-05\nEpoch 42/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.9047 - mae: 0.1738 - val_loss: 0.1060 - val_mae: 0.1384 - learning_rate: 7.5000e-05\nEpoch 43/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.9502 - mae: 0.1771 - val_loss: 0.1087 - val_mae: 0.1442 - learning_rate: 7.5000e-05\nEpoch 44/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.4895 - mae: 0.1705 - val_loss: 0.1060 - val_mae: 0.1369 - learning_rate: 7.5000e-05\nEpoch 45/200\n\u001b[1m193/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5877 - mae: 0.1667\nEpoch 45: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.5895 - mae: 0.1668 - val_loss: 0.1045 - val_mae: 0.1330 - learning_rate: 7.5000e-05\nEpoch 46/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.4491 - mae: 0.1680 - val_loss: 0.1039 - val_mae: 0.1312 - learning_rate: 3.7500e-05\nEpoch 47/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.9358 - mae: 0.1777 - val_loss: 0.1036 - val_mae: 0.1292 - learning_rate: 3.7500e-05\nEpoch 48/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.5482 - mae: 0.1657 - val_loss: 0.1047 - val_mae: 0.1320 - learning_rate: 3.7500e-05\nEpoch 49/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.6807 - mae: 0.1724 - val_loss: 0.1062 - val_mae: 0.1382 - learning_rate: 3.7500e-05\nEpoch 50/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1516 - mae: 0.1573 - val_loss: 0.1047 - val_mae: 0.1340 - learning_rate: 3.7500e-05\nEpoch 51/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.2787 - mae: 0.1611 - val_loss: 0.1058 - val_mae: 0.1373 - learning_rate: 3.7500e-05\nEpoch 52/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.3341 - mae: 0.1677 - val_loss: 0.1037 - val_mae: 0.1307 - learning_rate: 3.7500e-05\nEpoch 53/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.8832 - mae: 0.1846 - val_loss: 0.1058 - val_mae: 0.1363 - learning_rate: 3.7500e-05\nEpoch 54/200\n\u001b[1m192/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5078 - mae: 0.1626\nEpoch 54: ReduceLROnPlateau reducing learning rate to 1.8750000890577212e-05.\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.5084 - mae: 0.1627 - val_loss: 0.1049 - val_mae: 0.1339 - learning_rate: 3.7500e-05\nEpoch 55/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.5656 - mae: 0.1689 - val_loss: 0.1058 - val_mae: 0.1370 - learning_rate: 1.8750e-05\nEpoch 56/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.3759 - mae: 0.1742 - val_loss: 0.1063 - val_mae: 0.1389 - learning_rate: 1.8750e-05\nEpoch 57/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.0714 - mae: 0.1756 - val_loss: 0.1066 - val_mae: 0.1382 - learning_rate: 1.8750e-05\nEpoch 58/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.8126 - mae: 0.1763 - val_loss: 0.1052 - val_mae: 0.1343 - learning_rate: 1.8750e-05\nEpoch 59/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.7546 - mae: 0.1707 - val_loss: 0.1047 - val_mae: 0.1329 - learning_rate: 1.8750e-05\nEpoch 60/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.6837 - mae: 0.1713 - val_loss: 0.1055 - val_mae: 0.1348 - learning_rate: 1.8750e-05\nEpoch 61/200\n\u001b[1m194/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3062 - mae: 0.1845\nEpoch 61: ReduceLROnPlateau reducing learning rate to 9.375000445288606e-06.\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.2890 - mae: 0.1842 - val_loss: 0.1050 - val_mae: 0.1341 - learning_rate: 1.8750e-05\nEpoch 62/200\n\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1690 - mae: 0.1611 - val_loss: 0.1053 - val_mae: 0.1355 - learning_rate: 9.3750e-06\nEpoch 62: early stopping\nRestoring model weights from the end of the best epoch: 47.\nLSTM model and scalers saved successfully!\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n\nLSTM Training Metrics:\nRMSE: 33.6980, MAE: 9.0514\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ========================= TESTING PHASE =========================\n# Preprocess the testing data using the same scalers\nX_test, y_test = preprocess_test_data(testing_file, target_columns, scaler_X, scaler_y, look_back)\n\n# Predict and evaluate on the testing data\ny_test_pred = model.predict(X_test)\ny_test = scaler_y.inverse_transform(y_test)\ny_test_pred = scaler_y.inverse_transform(y_test_pred)\n\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntest_mae = mean_absolute_error(y_test, y_test_pred)\n\nprint(\"\\nLSTM Testing Metrics:\")\nprint(f\"RMSE: {test_rmse:.4f}, MAE: {test_mae:.4f}\")\n\n# Save predictions\ny_test_combined = pd.DataFrame(y_test, columns=target_columns)\ny_test_combined['Pred_Cloud_Throughput'] = y_test_pred[:, 0]\ny_test_combined['Pred_Total_Energy_Consumption'] = y_test_pred[:, 1]\ny_test_combined['Pred_Total_Exec_Time'] = y_test_pred[:, 2]\n\ny_test_combined.to_excel('testing_predictions_lstm_fixed.xlsx', index=False)\nprint(\"Testing predictions saved to 'testing_predictions_lstm_fixed.xlsx'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T00:54:04.159535Z","iopub.execute_input":"2025-01-10T00:54:04.159915Z","iopub.status.idle":"2025-01-10T00:54:04.988914Z","shell.execute_reply.started":"2025-01-10T00:54:04.159875Z","shell.execute_reply":"2025-01-10T00:54:04.987846Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\nLSTM Testing Metrics:\nRMSE: 34.1891, MAE: 19.3915\nTesting predictions saved to 'testing_predictions_lstm_fixed.xlsx'.\n","output_type":"stream"}],"execution_count":10}]}